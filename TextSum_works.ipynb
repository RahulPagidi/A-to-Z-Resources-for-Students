{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextSum - works.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RahulPagidi/A-to-Z-Resources-for-Students/blob/master/TextSum_works.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IviwGBdbC-d3",
        "colab_type": "code",
        "outputId": "e0f55795-3b7d-4f79-e304-3fbb04250079",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Htwcj1hmC_eW",
        "colab_type": "code",
        "outputId": "935afce8-9e50-4792-ce11-1d8982f56465",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGkUPIQ0DJzB",
        "colab_type": "code",
        "outputId": "00af9d74-c0ff-4e1d-c915-def9b7abdbdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evZjYKmdbvgL",
        "colab_type": "code",
        "outputId": "91302476-9228-4469-d68f-43dedf01feb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "import os\n",
        "import re\n",
        "import math\n",
        "import operator\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "Stopwords = set(stopwords.words('english'))\n",
        "wordlemmatizer = WordNetLemmatizer()\n",
        "def lemmatize_words(words):\n",
        "    lemmatized_words = []\n",
        "    for word in words:\n",
        "       lemmatized_words.append(wordlemmatizer.lemmatize(word))\n",
        "    return lemmatized_words\n",
        "def stem_words(words):\n",
        "    stemmed_words = []\n",
        "    for word in words:\n",
        "       stemmed_words.append(stemmer.stem(word))\n",
        "    return stemmed_words\n",
        "def remove_special_characters(text):\n",
        "    regex = r'[^a-zA-Z0-9\\s]'\n",
        "    text = re.sub(regex,'',text)\n",
        "    return text\n",
        "\n",
        "def remove_paranthesis(text):\n",
        "    pattern = r'\\[.*?\\]'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "def freq(words):\n",
        "    words = [word.lower() for word in words]\n",
        "    dict_freq = {}\n",
        "    words_unique = []\n",
        "    for word in words:\n",
        "       if word not in words_unique:\n",
        "           words_unique.append(word)\n",
        "    for word in words_unique:\n",
        "       dict_freq[word] = words.count(word)\n",
        "    return dict_freq\n",
        "def pos_tagging(text):\n",
        "    pos_tag = nltk.pos_tag(text.split())\n",
        "    pos_tagged_noun_verb = []\n",
        "    for word,tag in pos_tag:\n",
        "        if tag == \"NN\" or tag == \"NNP\" or tag == \"NNS\" or tag == \"VB\" or tag == \"VBD\" or tag == \"VBG\" or tag == \"VBN\" or tag == \"VBP\" or tag == \"VBZ\":\n",
        "             pos_tagged_noun_verb.append(word)\n",
        "    return pos_tagged_noun_verb\n",
        "def tf_score(word,sentence):\n",
        "    freq_sum = 0\n",
        "    word_frequency_in_sentence = 0\n",
        "    len_sentence = len(sentence)\n",
        "    for word_in_sentence in sentence.split():\n",
        "        if word == word_in_sentence:\n",
        "            word_frequency_in_sentence = word_frequency_in_sentence + 1\n",
        "    tf =  word_frequency_in_sentence/ len_sentence\n",
        "    return tf\n",
        "def idf_score(no_of_sentences,word,sentences):\n",
        "    no_of_sentence_containing_word = 0\n",
        "    for sentence in sentences:\n",
        "        sentence = remove_special_characters(str(sentence))\n",
        "        #sentence = re.sub(r'\\d+', '', sentence)\n",
        "        sentence = remove_paranthesis(str(sentence))\n",
        "        sentence = sentence.split()\n",
        "        sentence = [word for word in sentence if word.lower() not in Stopwords and len(word)>1]\n",
        "        sentence = [word.lower() for word in sentence]\n",
        "        sentence = [wordlemmatizer.lemmatize(word) for word in sentence]\n",
        "        if word in sentence:\n",
        "            no_of_sentence_containing_word = no_of_sentence_containing_word + 1\n",
        "    idf = math.log10(no_of_sentences/no_of_sentence_containing_word)\n",
        "    return idf\n",
        "def tf_idf_score(tf,idf):\n",
        "    return tf*idf\n",
        "def word_tfidf(dict_freq,word,sentences,sentence):\n",
        "    word_tfidf = []\n",
        "    tf = tf_score(word,sentence)\n",
        "    idf = idf_score(len(sentences),word,sentences)\n",
        "    tf_idf = tf_idf_score(tf,idf)\n",
        "    return tf_idf\n",
        "def sentence_importance(sentence,dict_freq,sentences):\n",
        "     sentence_score = 0\n",
        "     sentence = remove_special_characters(str(sentence)) \n",
        "     #sentence = re.sub(r'\\d+', '', sentence)\n",
        "     sentence = remove_paranthesis(str(sentence))\n",
        "     pos_tagged_sentence = [] \n",
        "     no_of_sentences = len(sentences)\n",
        "     pos_tagged_sentence = pos_tagging(sentence)\n",
        "     for word in pos_tagged_sentence:\n",
        "          if word.lower() not in Stopwords and word not in Stopwords and len(word)>1: \n",
        "                word = word.lower()\n",
        "                word = wordlemmatizer.lemmatize(word)\n",
        "                sentence_score = sentence_score + word_tfidf(dict_freq,word,sentences,sentence)\n",
        "     return sentence_score\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQSkidACQPHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file = '/content/drive/My Drive/Colab Notebooks/Akira/requirements.txt'\n",
        "file = open(file , 'r')\n",
        "text = file.read()\n",
        "tokenized_sentence = sent_tokenize(text)\n",
        "text = remove_special_characters(str(text))\n",
        "#text = re.sub(r'\\d+', '', text)\n",
        "text = remove_paranthesis(str(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ5rwEpjQRBb",
        "colab_type": "code",
        "outputId": "3eec67fb-332b-4681-ba9b-a0db60a58419",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "text"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Australia officially the Commonwealth of Australia12 is a sovereign country comprising the mainland of the Australian continent the island of Tasmania and numerous smaller islands It is the largest country in Oceania and the worlds sixthlargest country by total area The population of 26 million6 is highly urbanised and heavily concentrated on the eastern seaboard13 Australias capital is Canberra and its largest city is Sydney The countrys other major metropolitan areas are Melbourne Brisbane Perth and AdelaideIndigenous Australians inhabited the continent for about 65000 years14 prior to the first arrival of Dutch explorers in the early 17th century who named it New Holland In 1770 Australias eastern half was claimed by Great Britain and initially settled through penal transportation to the colony of New South Wales from 26 January 1788 a date which became Australias national day The population grew steadily in subsequent decades and by the time of an 1850s gold rush most ofthe continent had been explored and an additional five selfgoverning crown colonies established On 1 January 1901 the six colonies federated forming the Commonwealth of Australia Australia has since maintained a stable liberal democratic political system that functions as a federal parliamentary constitutional monarchy comprising six states and ten territories Australia is the oldest15 flattest16 and driest inhabited continent1718 with the least fertile soils1920 It has a landmass of 7617930 square kilometrs 2941300 sq mi21 A megadiverse country its size gives it a wide variety of landscapes with deserts in the centre tropical rainforests in the northeast and mountain ranges in the southeast Its population density 28 inhabitants per square kilometre remains among the lowest in the world22better source needed Australia generates its income from various sources including miningrelated exports telecommunications banking manufacturing and international education232425 Australia is a highly developed country with the worlds 14thlargest economy It has a highincome economy with the worlds tenthhighest per capita income26 It is a regional power and has the worlds 13thhighest military expenditure27 Australia has the worlds eighthlargest immigrant population with immigrants accounting for 29 of the population2829 Having the thirdhighest human development index and the eighthhighest ranked democracy globally the country ranks highly in quality of life health education economic freedom civil liberties and political rights30 with all its major cities faring well in global comparative livability surveys31 Australia is a member of the United Nations G20 Commonwealth of Nations ANZUS Organisation for Economic Cooperation and Development OECD World Trade Organization AsiaPacific Economic Cooperation Pacific Islands Forum and the ASEAN Plus Six mechanism'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    }
  ]
}